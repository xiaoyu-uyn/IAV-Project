{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import data\n",
    "import models, utils\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    utils.setup_experiment(args)\n",
    "    utils.init_logging(args)\n",
    "\n",
    "    # Build data loaders, a model and an optimizer\n",
    "    model = models.build_model(args).to(device)\n",
    "    print(model)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 60, 70, 80, 90, 100], gamma=0.5)\n",
    "    logging.info(f\"Built a model consisting of {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "\n",
    "    if args.resume_training:\n",
    "        state_dict = utils.load_checkpoint(args, model, optimizer, scheduler)\n",
    "        global_step = state_dict['last_step']\n",
    "        start_epoch = int(state_dict['last_step']/(403200/state_dict['args'].batch_size))+1\n",
    "    else:\n",
    "        global_step = -1\n",
    "        start_epoch = 0\n",
    "\n",
    "    train_loader, valid_loader, _ = data.build_dataset(args.dataset, args.data_path, batch_size=args.batch_size)\n",
    "\n",
    "    # Track moving average of loss values\n",
    "    train_meters = {name: utils.RunningAverageMeter(0.98) for name in ([\"train_loss\", \"train_psnr\", \"train_ssim\"])}\n",
    "    valid_meters = {name: utils.AverageMeter() for name in ([\"valid_psnr\", \"valid_ssim\"])}\n",
    "    writer = SummaryWriter(log_dir=args.experiment_dir) if not args.no_visual else None\n",
    "\n",
    "    for epoch in range(start_epoch, args.num_epochs):\n",
    "        if args.resume_training:\n",
    "            if epoch %10 == 0:\n",
    "                optimizer.param_groups[0][\"lr\"] /= 2\n",
    "                print('learning rate reduced by factor of 2')\n",
    "\n",
    "        train_bar = utils.ProgressBar(train_loader, epoch)\n",
    "        for meter in train_meters.values():\n",
    "            meter.reset()\n",
    "\n",
    "        for batch_id, inputs in enumerate(train_bar):\n",
    "            model.train()\n",
    "\n",
    "            global_step += 1\n",
    "            inputs = inputs.to(device)\n",
    "            noise = utils.get_noise(inputs, mode = args.noise_mode, \n",
    "                                                min_noise = args.min_noise/255., max_noise = args.max_noise/255.,\n",
    "                                                noise_std = args.noise_std/255.)\n",
    "\n",
    "            noisy_inputs = noise + inputs;\n",
    "            outputs = model(noisy_inputs)\n",
    "            loss = F.mse_loss(outputs, inputs, reduction=\"sum\") / (inputs.size(0) * 2)\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_psnr = utils.psnr(outputs, inputs)\n",
    "            train_ssim = utils.ssim(outputs, inputs)\n",
    "            train_meters[\"train_loss\"].update(loss.item())\n",
    "            train_meters[\"train_psnr\"].update(train_psnr.item())\n",
    "            train_meters[\"train_ssim\"].update(train_ssim.item())\n",
    "            train_bar.log(dict(**train_meters, lr=optimizer.param_groups[0][\"lr\"]), verbose=True)\n",
    "\n",
    "            if writer is not None and global_step % args.log_interval == 0:\n",
    "                writer.add_scalar(\"lr\", optimizer.param_groups[0][\"lr\"], global_step)\n",
    "                writer.add_scalar(\"loss/train\", loss.item(), global_step)\n",
    "                writer.add_scalar(\"psnr/train\", train_psnr.item(), global_step)\n",
    "                writer.add_scalar(\"ssim/train\", train_ssim.item(), global_step)\n",
    "                gradients = torch.cat([p.grad.view(-1) for p in model.parameters() if p.grad is not None], dim=0)\n",
    "                writer.add_histogram(\"gradients\", gradients, global_step)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        if epoch % args.valid_interval == 0:\n",
    "            model.eval()\n",
    "            for meter in valid_meters.values():\n",
    "                meter.reset()\n",
    "\n",
    "            valid_bar = utils.ProgressBar(valid_loader)\n",
    "            for sample_id, sample in enumerate(valid_bar):\n",
    "                with torch.no_grad():\n",
    "                    sample = sample.to(device)\n",
    "                    noise = utils.get_noise(sample, mode = 'S', \n",
    "                                                noise_std = (args.min_noise +  args.max_noise)/(2*255.))\n",
    "\n",
    "                    noisy_inputs = noise + sample;\n",
    "                    output = model(noisy_inputs)\n",
    "                    valid_psnr = utils.psnr(output, sample)\n",
    "                    valid_meters[\"valid_psnr\"].update(valid_psnr.item())\n",
    "                    valid_ssim = utils.ssim(output, sample)\n",
    "                    valid_meters[\"valid_ssim\"].update(valid_ssim.item())\n",
    "\n",
    "                    if writer is not None and sample_id < 10:\n",
    "                        image = torch.cat([sample, noisy_inputs, output], dim=0)\n",
    "                        image = torchvision.utils.make_grid(image.clamp(0, 1), nrow=3, normalize=False)\n",
    "                        writer.add_image(f\"valid_samples/{sample_id}\", image, global_step)\n",
    "\n",
    "            if writer is not None:\n",
    "                writer.add_scalar(\"psnr/valid\", valid_meters['valid_psnr'].avg, global_step)\n",
    "                writer.add_scalar(\"ssim/valid\", valid_meters['valid_ssim'].avg, global_step)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            logging.info(train_bar.print(dict(**train_meters, **valid_meters, lr=optimizer.param_groups[0][\"lr\"])))\n",
    "            utils.save_checkpoint(args, global_step, model, optimizer, score=valid_meters[\"valid_psnr\"].avg, mode=\"max\")\n",
    "        scheduler.step()\n",
    "\n",
    "    logging.info(f\"Done training! Best PSNR {utils.save_checkpoint.best_score:.3f} obtained after step {utils.save_checkpoint.best_step}.\")\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(allow_abbrev=False)\n",
    "\n",
    "    # Add data arguments\n",
    "    parser.add_argument(\"--data-path\", default=\"/Users/qiao/Documents/IAV_Processing/Project/BFDnCNN/bias_free_denoising-master/data/\", help=\"path to data directory\")\n",
    "    parser.add_argument(\"--dataset\", default=\"bsd400\", help=\"train dataset name\")\n",
    "    parser.add_argument(\"--batch-size\", default=128, type=int, help=\"train batch size\")\n",
    "\n",
    "    # Add model arguments\n",
    "    parser.add_argument(\"--model\", default=\"dncnn\", help=\"model architecture\")\n",
    "\n",
    "    # Add noise arguments\n",
    "    parser.add_argument(\"--noise_mode\", default=\"B\", help=\"B - Blind S-one noise level\")\n",
    "    parser.add_argument('--noise_std', default = 25, type = float, \n",
    "                help = 'noise level when mode is S')\n",
    "    parser.add_argument('--min_noise', default = 0, type = float, \n",
    "                help = 'minimum noise level when mode is B')\n",
    "    parser.add_argument('--max_noise', default = 30, type = float,\n",
    "                    help = 'maximum noise level when mode is B')\n",
    "\n",
    "    # Add optimization arguments\n",
    "    parser.add_argument(\"--lr\", default=1e-3, type=float, help=\"learning rate\")\n",
    "    parser.add_argument(\"--num-epochs\", default=100, type=int, help=\"force stop training at specified epoch\")\n",
    "    parser.add_argument(\"--valid-interval\", default=1, type=int, help=\"evaluate every N epochs\")\n",
    "    parser.add_argument(\"--save-interval\", default=1, type=int, help=\"save a checkpoint every N steps\")\n",
    "\n",
    "    # Parse twice as model arguments are not known the first time\n",
    "    parser = utils.add_logging_arguments(parser)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    models.MODEL_REGISTRY[args.model].add_args(parser)\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = get_args()\n",
    "    main(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
